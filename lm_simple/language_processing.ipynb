{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "from collections import defaultdict\n",
    "import sys, re\n",
    "import pandas as pd\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done vocabularizing document\n",
      "Processed data/train.txt\n",
      "Done vocabularizing document\n",
      "Processed data/test.txt\n",
      "Done vocabularizing document\n",
      "Processed data/valid.txt\n"
     ]
    }
   ],
   "source": [
    "train_file = \"../data/train.txt\"\n",
    "test_file = \"../data/test.txt\"\n",
    "valid_file = \"../data/valid.txt\"\n",
    "\n",
    "gram_size = 5\n",
    "\n",
    "def process(files, gram_size):\n",
    "    eos = 1\n",
    "    vocab = {'/s':eos} # don't zero index\n",
    "    rev_vocab = {eos: '/s'}\n",
    "    counter = eos+1\n",
    "    datas = []\n",
    "    targets = []\n",
    "    \n",
    "    for file_n in files:\n",
    "                \n",
    "        target = []\n",
    "        data = []\n",
    "        text = []\n",
    "        with open(file_n, \"rb\") as f:\n",
    "        # use collections lib to build vocab super quickly?\n",
    "\n",
    "            for line in f:\n",
    "                ints = []\n",
    "                words = line.split()\n",
    "                for word in words:\n",
    "                    try:\n",
    "                        ints.append(vocab[word])\n",
    "                    except:\n",
    "                        vocab[word] = counter\n",
    "                        rev_vocab[counter] = word\n",
    "                        counter += 1\n",
    "                        ints.append(vocab[word])\n",
    "\n",
    "                    '''\n",
    "                    if word not in vocab.keys():\n",
    "                        vocab[word] = counter\n",
    "                        counter += 1\n",
    "                    ints.append(vocab[word])\n",
    "                    '''\n",
    "                text.append(ints)\n",
    "            print \"Done vocabularizing document\"\n",
    "                \n",
    "            for line in text:\n",
    "                for i in xrange(len(line) - gram_size+1):\n",
    "                    data.append(line[i:i+gram_size])\n",
    "                    if i+gram_size >= len(line):\n",
    "                        target.append(eos)\n",
    "                    else:\n",
    "                        target.append(line[i+gram_size])\n",
    "        targets.append(target)\n",
    "\n",
    "        datas.append(data)\n",
    "        print \"Processed\", file_n  \n",
    "    \n",
    "    return datas, targets, vocab, rev_vocab\n",
    "\n",
    "data, targets, vocab, rev = process([train_file, test_file, valid_file], gram_size)\n",
    "\n",
    "train = np.array(data[0])\n",
    "train_t = np.array(targets[0])\n",
    "test = np.array(data[1])\n",
    "test_t = np.array(targets[1])\n",
    "valid = np.array(data[2])\n",
    "valid_t = np.array(targets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pickle.dump(vocab, open('vocab.pickle', 'wb'))\n",
    "\n",
    "with h5py.File(\"language5.hdf5\", \"w\") as f:\n",
    "    dset1 = f.create_dataset(\"train\", data=train)\n",
    "    dset2 = f.create_dataset(\"train_t\", data=train_t)\n",
    "    dset3 = f.create_dataset(\"test\", data=test)\n",
    "    dset4 = f.create_dataset(\"test_t\", data=test_t)\n",
    "    dset5 = f.create_dataset(\"valid\", data=valid)\n",
    "    dset6 = f.create_dataset(\"valid_t\", data=valid_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = h5py.File(\"language_preds.hdf5\")\n",
    "\n",
    "predictions = f['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 it was n't black monday /s /s\n",
      "2 but while the new york stock /s\n",
      "3 while the new york stock exchange stock\n",
      "4 the new york stock exchange did exchange\n",
      "5 new york stock exchange did n't composite\n",
      "6 york stock exchange did n't fall n't\n",
      "7 stock exchange did n't fall apart comment\n",
      "8 exchange did n't fall apart friday /s\n",
      "9 did n't fall apart friday as /s\n",
      "10 n't fall apart friday as the 's\n",
      "11 fall apart friday as the dow much\n",
      "12 apart friday as the dow jones <unk>\n",
      "13 friday as the dow jones industrial jones\n",
      "14 as the dow jones industrial average industrial\n",
      "15 the dow jones industrial average plunged average\n",
      "16 dow jones industrial average plunged N fell\n",
      "17 jones industrial average plunged N points N\n",
      "18 industrial average plunged N points most points\n",
      "19 average plunged N points most of to\n",
      "20 plunged N points most of it <unk>\n",
      "21 N points most of it in the\n",
      "22 points most of it in the was\n",
      "23 most of it in the final N\n",
      "24 of it in the final hour <unk>\n",
      "25 it in the final hour it <unk>\n",
      "26 in the final hour it barely of\n",
      "27 the final hour it barely managed was\n",
      "28 final hour it barely managed to N\n",
      "29 hour it barely managed to stay /s\n",
      "30 it barely managed to stay this <unk>\n",
      "31 barely managed to stay this side in\n",
      "32 managed to stay this side of week\n",
      "33 to stay this side of chaos /s\n",
      "34 stay this side of chaos /s the\n",
      "35 some circuit breakers installed after the /s\n",
      "36 circuit breakers installed after the october the\n",
      "37 breakers installed after the october N <unk>\n",
      "38 installed after the october N crash N\n",
      "39 after the october N crash failed of\n",
      "40 the october N crash failed their /s\n",
      "41 october N crash failed their first to\n",
      "42 N crash failed their first test <unk>\n",
      "43 crash failed their first test traders <unk>\n",
      "44 failed their first test traders say is\n",
      "45 their first test traders say unable say\n",
      "46 first test traders say unable to /s\n",
      "47 test traders say unable to cool to\n",
      "48 traders say unable to cool the get\n",
      "49 say unable to cool the selling the\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(1, 50):\n",
    "    print i,\n",
    "    for j in xrange(len(test[i])):\n",
    "        print rev[test[i][j]],\n",
    "    print rev[test_t[i]], rev[predictions[i]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
